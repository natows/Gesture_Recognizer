import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt

# Parametry
SEQ_LENGTH = 10  # liczba klatek w sekwencji
N_LANDMARKS = 21  # liczba punktÃ³w dÅ‚oni
N_COORDS = 2     # x, y wspÃ³Å‚rzÄ™dne

print("ğŸ¬ LSTM Gesture Recognition Training")
print("=" * 50)

# 1. Wczytanie danych
print("ğŸ“‚ Wczytywanie danych...")
df = pd.read_csv('../data_sources/sequences.csv')
print(f"ğŸ“Š Wczytano {len(df)} sekwencji")

# SprawdÅº rozkÅ‚ad gestÃ³w
print("\nğŸ“ˆ RozkÅ‚ad gestÃ³w:")
gesture_counts = df['label'].value_counts()
for gesture, count in gesture_counts.items():
    print(f"  {gesture}: {count} sekwencji")

# 2. Przetwarzanie danych
print("\nğŸ”§ Przetwarzanie danych...")

# WyodrÄ™bnij features (wszystko oprÃ³cz label)
feature_columns = [col for col in df.columns if col != 'label']
X = df[feature_columns].values
y = df['label'].values

print(f"ğŸ“ KsztaÅ‚t X: {X.shape}")
print(f"ğŸ“ Liczba cech na klatkÄ™: {len(feature_columns) // SEQ_LENGTH}")

# PrzeksztaÅ‚Ä‡ dane do formatu LSTM: (samples, timesteps, features)
# X.shape = (n_samples, seq_length * n_features_per_frame)
# Chcemy: (n_samples, seq_length, n_features_per_frame)

n_samples = X.shape[0]
n_features_per_frame = len(feature_columns) // SEQ_LENGTH  # 42 (21 * 2)

# Reshape danych
X_reshaped = X.reshape(n_samples, SEQ_LENGTH, n_features_per_frame)
print(f"ğŸ”„ Dane po reshape: {X_reshaped.shape}")

# 3. Enkodowanie etykiet
print("\nğŸ·ï¸ Enkodowanie etykiet...")
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = to_categorical(y_encoded)

print(f"ğŸ“‹ Klasy: {list(label_encoder.classes_)}")
print(f"ğŸ“Š Liczba klas: {len(label_encoder.classes_)}")

# 4. PodziaÅ‚ danych
print("\nâœ‚ï¸ PodziaÅ‚ danych...")
X_train, X_test, y_train, y_test = train_test_split(
    X_reshaped, y_categorical, 
    test_size=0.2, 
    random_state=42, 
    stratify=y_encoded
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, 
    test_size=0.2, 
    random_state=42
)

print(f"ğŸš‚ Trening: {X_train.shape[0]} prÃ³bek")
print(f"âœ… Walidacja: {X_val.shape[0]} prÃ³bek") 
print(f"ğŸ§ª Test: {X_test.shape[0]} prÃ³bek")

# 5. Budowa modelu LSTM
print("\nğŸ—ï¸ Budowa modelu LSTM...")

model = Sequential([
    # Pierwsza warstwa LSTM
    LSTM(128, return_sequences=True, 
         input_shape=(SEQ_LENGTH, n_features_per_frame),
         name='lstm_1'),
    BatchNormalization(),
    Dropout(0.3),
    
    # Druga warstwa LSTM
    LSTM(64, return_sequences=True, name='lstm_2'),
    BatchNormalization(), 
    Dropout(0.3),
    
    # Trzecia warstwa LSTM
    LSTM(32, return_sequences=False, name='lstm_3'),
    BatchNormalization(),
    Dropout(0.4),
    
    # Warstwy Dense
    Dense(64, activation='relu', name='dense_1'),
    Dropout(0.5),
    
    Dense(32, activation='relu', name='dense_2'),
    Dropout(0.3),
    
    # Warstwa wyjÅ›ciowa
    Dense(len(label_encoder.classes_), activation='softmax', name='output')
])

# Kompilacja
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nğŸ“‹ Architektura modelu:")
model.summary()

# 6. Callbacks
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=15,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=8,
        min_lr=1e-7,
        verbose=1
    )
]

# 7. Trenowanie
print("\nğŸš€ Rozpoczynanie treningu...")
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=100,
    batch_size=16,
    callbacks=callbacks,
    verbose=1
)

# 8. Ewaluacja
print("\nğŸ“Š Ewaluacja modelu...")
train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)

print(f"ğŸš‚ Trening - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}")
print(f"âœ… Walidacja - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")
print(f"ğŸ§ª Test - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}")

# 9. Predykcje i analiza
print("\nğŸ” Analiza predykcji...")
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Classification report
from sklearn.metrics import classification_report, confusion_matrix
print("\nğŸ“‹ Raport klasyfikacji:")
print(classification_report(
    y_true_classes, y_pred_classes, 
    target_names=label_encoder.classes_
))

# Confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)
print("\nğŸ”¢ Macierz pomyÅ‚ek:")
print(cm)

# 10. Wykresy treningu
print("\nğŸ“Š Generowanie wykresÃ³w...")
plt.figure(figsize=(15, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Trening', linewidth=2)
plt.plot(history.history['val_accuracy'], label='Walidacja', linewidth=2)
plt.title('DokÅ‚adnoÅ›Ä‡ modelu LSTM', fontsize=14, fontweight='bold')
plt.xlabel('Epoka')
plt.ylabel('DokÅ‚adnoÅ›Ä‡')
plt.legend()
plt.grid(True, alpha=0.3)

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Trening', linewidth=2)
plt.plot(history.history['val_loss'], label='Walidacja', linewidth=2)
plt.title('Strata modelu LSTM', fontsize=14, fontweight='bold')
plt.xlabel('Epoka')
plt.ylabel('Strata')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('lstm_training_history.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nğŸ’¾ Zapisywanie modelu...")
import os
os.makedirs('models/LSTM', exist_ok=True)

model.save('models/LSTM/lstm_gesture_model.keras')
print("âœ… Model zapisany: models/LSTM/lstm_gesture_model.keras")

import pickle
with open('models/LSTM/label_encoder_lstm.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)
print("âœ… Label encoder zapisany: models/LSTM/label_encoder_lstm.pkl")

model_info = {
    'sequence_length': SEQ_LENGTH,
    'n_landmarks': N_LANDMARKS,
    'n_coords': N_COORDS,
    'n_features_per_frame': n_features_per_frame,
    'classes': list(label_encoder.classes_),
    'test_accuracy': test_acc,
    'input_shape': X_reshaped.shape[1:]
}

import json
with open('models/LSTM/model_info.json', 'w') as f:
    json.dump(model_info, f, indent=2)
print("âœ… Info o modelu zapisane: models/LSTM/model_info.json")

print(f"\nğŸ‰ TRENOWANIE ZAKOÅƒCZONE!")
print(f"ğŸ† Finalna dokÅ‚adnoÅ›Ä‡: {test_acc:.2%}")
print("=" * 50)